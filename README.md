文本审核模块
========
minitrill 文本审核模块

## 模块架构
基本模块架构如下

![](https://upload-images.jianshu.io/upload_images/5617720-4e2fbdd21464bd77.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
#### 模块划分
整个文本审核主要分为两个模块
1. [文本处理模块](#文本处理)(基础)
2. [审核策略模块](#审核策略)(核心)
![](https://upload-images.jianshu.io/upload_images/5617720-4ee26dd36d3c276b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
#### 审核范围
审核范围包括所用用户产生的文字信息,按照重要程度主要分为以下三类
- 发布内容(视频标题,用户简介,视频评论...)
- 资料内容(用户名,视频简介...)
- 其他内容(私信数据...)

#### 核心思路
文本审核的核心思路是对数据进行**量化**     
对于应用中出现恶意文本的场景,我们可以做以下分类        

- 频率
  - 因为与其他用户的争执而偶尔发生的谩骂(偶尔) 
  - 非法组织在平台上的扩散与传播(频繁)
  - 因为背后利益驱动而发送垃圾广告,色情信息(非常频繁)
- 分类/意图
  - 颠覆国家政权,调侃领导人(极其严重)
  - 政治,邪教,敏感言论(非常严重)
  - 色情,违法,广告(一般严重)
  - 谩骂,侮辱,谣言(轻微)
- 传播范围
  - 意见领袖或者大V的恶意言论(影响力大)
  - 普通用户的恶意言论(影响力小)
  - 用户个人详细信息中的恶意信息(传播度小)
  - 用户头像,昵称中的恶意信息(传播度大)

```diff
+ 希望对于不同的场景不同的目标人群,采取不同的打击策略和应对手段     
+ 在维护平台内容安全的前提下,尽可能提高用户体验     
+ 鉴别和发现**持续有害**的用户进行打击
- 可以防止粗暴的一刀切策略影响用户体验      
- 对于有些文本即使单单进行关键词过滤也无法阻止其生效或表达
```

## 文本处理
本子模块主要用于处理文本,主动发现并量化恶意.

### 1. 基于敏感词的文本审核及过滤
基于DFA通过tire树实现了一个高效的敏感词过滤器,可发现文本中的所有敏感词及其类型     
并根据发现的敏感词类型对语句分类,基于敏感词权重对语句进行恶意度判定

#### 实现功能
1. 共收录了6类,共744个敏感词数据
2. 基于数据库或者txt文件初始化分类初始化敏感词列表
3. 支持动态添加敏感词及类别,并可以将当前数据持久化到文件中
4. 判别语句中是否含有敏感词(默认贪婪,匹配所有敏感词)
5. 过滤语句,可以自定义过滤字符
6. 基于语句中的敏感词对句子进行恶意类别判定及恶意度量化

#### 使用方法
入口及使用方法详见 `text_filter.py`
```python
from text_filter import TextFilter

t = TextFilter()     # 初始化                      # 贪婪模式,匹配所有敏感词
t.is_contain('气死我了,卧槽. 免费提供无抵押贷款')       # 监测是否有敏感词,返回(敏感词在字符串的起始位置,敏感词,敏感词类型)构成的列表
[(5, u'\u5367\u69fd', 'dirty'), (13, u'\u65e0\u62b5\u62bc\u8d37\u6b3e', 'ad')]
t.filter('习近平修宪')                               # 敏感词过滤 str
# ***修宪
t.filter(u'卧槽,我真是草泥马')                        # 敏感词过滤 unicode
# **,我真是***
t.filter(u'法论功大发好,真善忍好',replace_char=u'-')   # 敏感词过滤,指定替换字符
# ---大发好,真善忍好
t.filter('高效低价英雄联盟代练')                       # 测试添加敏感词功能
# 高效低价英雄联盟代练
t.add_word(u'英雄联盟代练')
t.filter('高效低价英雄联盟代练')
# 高效低价******
# >>>t.classifie('气死我了,卧槽. 免.费提供.无抵押.贷款') # 基于敏感词的语句分类及恶意度量化(过滤无用字符)
# {'massage type': 'ad',
# 'malicious count': 15.0,
# 'malicious info': {'dirty': 5.0, 'ad': 10.0},
# 'massage details':[(4, u'\u5367\u69fd', 'dirty', 5.0), 
#                   (10, u'\u65e0\u62b5\u62bc\u8d37\u6b3e', 'ad', 10.0)]
# }
```
#### 性能测试
与python自建的in,replace性能比对

**测试集1**         
语句数量 10,000        
敏感词数量 744      

| 文本过滤器 | 运行时间(s) | 语句平均运行时间(个/ms)|
| :------ | :------ | :------ |
| 基于DFA的文本过滤器 | 0.0590 | 0.0059 |
| 朴素文本过滤器 | 0.2730 | 0.0273 |

**测试集2**
语句数量 10000            
敏感词数量 15000 
    
| 文本过滤器 | 运行时间(s) | 语句平均运行时间(个/ms)|
| :------ | :------ | :------ |
| 基于DFA的文本过滤器 | 0.420 | 0.042 |
| 朴素文本过滤器 | 6.5060 | 0.6506 |

可以看到DFA方式的文本过滤器的速度基本是朴素写法的十倍左右              
在敏感词数据量增加的情况下性能表现也更稳定.

### 2. 基于文本分类的审核
是基于TF-IDF通过sklearn的实现的文本分类器及停用词,数据集持久化相关功能      
主要用于处理文本过滤时发现敏感词,但健康度数据介于处理与掠过区间的文本     
判断完成文本类型后,判断的文本类型后将本条数据进行记录

#### 使用说明
入口见```text_classifie.py```
```python
# 文本分类器初始化
t = TextClassifie()          # 初始化
t.set_classifie_model()      # 选择分类器模型
t.init_clf()                 # 分类器初始化(支持6种分类器模型,并且可以指定模型参数)
# 数据集构建
d = DataSet()                # 构建数据集
d.set_labels(["人", "物"])                        # 设置标签
d.add_data("我叫jerry", 'train_data_1', data_labels='人')  # 添加数据(文本,id,标签)
d.add_data("这个是桌子", 'train_data_2', data_labels='物体')
tarin_data = d.train2tf_idf()                         # 生成tf-idf向量数据
# 数据集持久化,读取数据集
train_data.save_tf_idf_data()                         # 保存数据到文件中
train_data.read_tf_idf_data()                         # 从文件中读取数据
# 分类模型训练及比较
t.train(tarin_data)                                   # 训练模型
t.predicted(tarin_data)                               # 对数据进行文本分类(这里用训练数据代替,用同样的方式可以生成测试数据
# ['人','物体']
t.metrics_result()
# 比对模型精度(只针对打好标签的训练集)
```

#### 实现功能
* 数据集
  - 自定义数据集标签集,自主添加数据
  - 使用停用词集过滤分词后的数据,并保持原语句顺序
  - 分词数据转化为TF-IDF空间向量数据
  - 支持基于PCA算法对矩阵进行降维
  - 支持持久化到磁盘中/从磁盘中读取已经训练好的数据集
  
* 分类器
  - 支持多种分类器模型进行文本分类
  - 支持持久化模型当前状态到磁盘中
  - 测试集精度及性能对比
  
  
#### 性能测试
这里采用了 [文本分类语料库（复旦）测试语料](http://www.nlpir.org/?action-viewnews-itemid-103) 来进行文本分类测试      
共 **20种** 文章分类, **9374篇** 文档,共约120M,按照**7:3划分训练/测试集**进行文本分类测试       
基于 sklearn 和 TF-IDF 结合不同文本分类模型来进行文本分类测试      
文本分类测试结果如下 

| 文本分类器 | 训练时间(s) | 分类时间(s) | 精度 | 召回 | f1 |
| :------ | :------ | :------ | :------ | :------ | :------ |
| 多项式贝叶斯(alpha=0.1) | 0.2850 | 0.0720 | 0.77723 | 0.78500 | 0.75392 |
| 多项式贝叶斯(alpha=0.01) | 0.2810 | 0.0720 | 0.85151 | 0.85221 | 0.83334 |
| 多项式贝叶斯(alpha=0.001) | 0.2950 | 0.0740 | 0.86374 | 0.87003 | 0.85894 |
| 多项式贝叶斯(alpha=0.0001) | 0.2800 | 0.0710 | 0.86432 | 0.86929 | 0.85785 |
| 支持向量机SVM | 182.2480 | 54.6420 | 0.03297 | 0.18158 | 0.05581 |
| 决策树 | 13.9700 | 0.0410 | 0.84313 | 0.84033 | 0.84039 |
| 逻辑回归 | 13.3400 | 0.0520 | 0.82730 | 0.86558 | 0.84040 |
| 随机森林(n=10) | 4.1970 | 0.1100 | 0.77579 | 0.77089 | 0.75014 |
| 随机森林(n=20) | 8.1570 | 0.1830 | 0.82469 | 0.81545 | 0.79146 |
| 随机森林(n=25) | 10.6610 | 0.2110  | 0.83221 | 0.82436 | 0.80422 |
| 随机森林(n=30) | 14.1020 | 0.2810 | 0.83121 | 0.81730 |0.79248 |
| kNN聚类(n) | 0.0210 | 3.1180 | 0.84410 | 0.86075 | 0.84292 |
| kNN聚类(n+1) | 0.0220 | 3.2940 | 0.84291 | 0.85964 | 0.84207 |
| kNN聚类(n+2) | 0.0210 | 3.2700 | 0.84319 | 0.86038 | 0.84310 |
| kNN聚类(2n) | 0.0210 | 3.1490 | 0.83054 | 0.84515 | 0.82371 |
| GBDT(默认) | 1848.1790 | 0.1210 | 0.90521 | 0.90791 | 0.90005 |
| GBDT(0.05,150) | 2871.2200 | 0.1640 | 0.90646 | 0.91125 | 0.90331 |

可见,经过简单调参之后GBDT的分类效果最好,可达 **90%+**

### 3. 针对于热度数据的人工审核接口
这里的可以视为对1,2方式的补足,主要针对以下场景. 并且审核数据可反馈1,2方式数据集

#### 作用范围
1. 传播度非常大的言论
2. 被举报多次,无法被系统识别的言论
3. 及其隐晦的政治、敏感言论

### 接口提供辅助数据
审核接口在提供需要审核的文本时也会提供一些其他数据共审核者参考

* 对于被审核文本的数据
  - 文本过滤结果
  - 文本审核结果
  - 目前文本的健康度
  
* 关联文本产生人的数据
  - 此用户近期发表言论数
  - 此用户近期健康度
  - 此用户近期被文本审核模块记录的次数
  - 此用户的影响力(粉丝数,视频数,视频点击量,喜欢数) *不展示用户个人及隐私信息*

#### 人工审核数据生成方式

1. 每日 TOP1%(基于点击量) 视频标题,简介,及热评
2. 平台热评 TOP 1K(基于评论赞数)
3. 每日举报度(举报数 / √点击量 或 喜欢数) TOP 100 (*防止恶意举报?*)

#### 审核处理方式
审核接口可直接决定该文本及对应用户的处理措施
具体处理措施详见下方处理策略

## 审核策略
本子模块主要用与对文本处理模型所发现恶意言论进行处理和打击

### 发现策略
主要是量化经文本处理模块所处理的文本数据

#### 语句健康度
这里引入一个语句健康度的概念来标示语句的恶意程度        
健康度越小恶意程度越大

不同类别的敏感词基础分值如下
**文本频率权重**

| 类别 | 权重 |
| :------ | :------ | 
| 昵称/视频标题 | 1.5 |
| 个人简介/视频简介 |1.2 |
| 视频评论 | 1.0 |
| 私信 | 0.7 |

**敏感词严重程度表**
       
| 类别 | 词默认权重 |
| :------ | :------ | 
| 政治敏感 | 35 |
| 反动言论 |30 |
| 非法 |30 |
| 广告 |25|
| 色情 |20 |
| 脏话 |5 |    

**语句分类**            
被文本分类器分类为恶意的语句会扣除相应的默认权重值,并被记录


**语句健康度计算方法**       
语句默认健康度为100
文本过滤和文本分类处理过的文本会扣除相应的健康度

```
MH(语句健康度) = 100 - (语句中敏感词1权重 + 语句中敏感词2权重 + ... + (文本分类器所分类别权重)) x 文本频率权重 x 审核阈值 
```
审核阈值默认为 1.0 可以通过配置文件进行修改( 0.5 ~ 2.0 )来控制整体审核程度

**敏感词权重的处理思路**         
1. 词 A 若在本类别中代表性越大,则权重越大         
2. 词 A 所在的类别危害程度越大,则权重越大
*敏感词权重范围(0~100)*

每隔一段时间会收集所有恶意类别的文本,根据词频记录新增的敏感词汇

#### 用户健康度
用户健康度标志着用户言论和行为的恶意程度.
每一条语句健康度过低的文本都会降低用户健康度
每个月用户都会自主回复一定程度的健康度

1. 用户健康度默认值为100,上为100
2. 用户健康度每周会上升 10 点(不会超过上限)
3. 用户每条被`记录`的文本回扣扣除 0.05 * (100 - 被记录文本健康度) 健康度
4. 用户每条被`警告/强迫修改/仅自己可见`会扣除 0.1 * (100 - 文本健康度) 健康度
5. 用户每条被`删除`的文本会扣除20健康度


### 处理策略

**针对语句健康度的处理策略**

| 健康度范围 | 处理策略 |
| :------ | :------ | 
| >90 | 不做任何处理 |
| 90~60 | 记录本次文本数据 |
| 60~40 | 警告/强迫修改/仅自己可见/SAGE |
| <40 | 直接删除 |

**针对用户健康度的处理策略**

| 健康度范围 | 处理策略 |
| :------ | :------ | 
| >80 | 不做任何处理 |
| 60~80 | 无法发布新视频/评论 |
| <60 | 永久封禁 |